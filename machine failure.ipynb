{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c94b39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "647657d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ddfcc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, KFold,  GridSearchCV,  RandomizedSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "742f2fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./train.csv\")\n",
    "\n",
    "test = pd.read_csv(\"./test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea9072e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['L', 'M', 'H'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"Type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba8026ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Type'] = dataset['Type'].replace({\"L\": 0, \"M\": 1, \"H\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fddf69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Type'] = dataset['Type'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20c636fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Air temperature [K]</th>\n",
       "      <th>Process temperature [K]</th>\n",
       "      <th>Rotational speed [rpm]</th>\n",
       "      <th>Torque [Nm]</th>\n",
       "      <th>Tool wear [min]</th>\n",
       "      <th>Machine failure</th>\n",
       "      <th>TWF</th>\n",
       "      <th>HDF</th>\n",
       "      <th>PWF</th>\n",
       "      <th>OSF</th>\n",
       "      <th>RNF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>L50096</td>\n",
       "      <td>0</td>\n",
       "      <td>300.6</td>\n",
       "      <td>309.6</td>\n",
       "      <td>1596</td>\n",
       "      <td>36.1</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>M20343</td>\n",
       "      <td>1</td>\n",
       "      <td>302.6</td>\n",
       "      <td>312.1</td>\n",
       "      <td>1759</td>\n",
       "      <td>29.1</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>L49454</td>\n",
       "      <td>0</td>\n",
       "      <td>299.3</td>\n",
       "      <td>308.5</td>\n",
       "      <td>1805</td>\n",
       "      <td>26.5</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>L53355</td>\n",
       "      <td>0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>310.9</td>\n",
       "      <td>1524</td>\n",
       "      <td>44.3</td>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>M24050</td>\n",
       "      <td>1</td>\n",
       "      <td>298.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>1641</td>\n",
       "      <td>35.4</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id Product ID Type  Air temperature [K]  Process temperature [K]  \\\n",
       "0   0     L50096    0                300.6                    309.6   \n",
       "1   1     M20343    1                302.6                    312.1   \n",
       "2   2     L49454    0                299.3                    308.5   \n",
       "3   3     L53355    0                301.0                    310.9   \n",
       "4   4     M24050    1                298.0                    309.0   \n",
       "\n",
       "   Rotational speed [rpm]  Torque [Nm]  Tool wear [min]  Machine failure  TWF  \\\n",
       "0                    1596         36.1              140                0    0   \n",
       "1                    1759         29.1              200                0    0   \n",
       "2                    1805         26.5               25                0    0   \n",
       "3                    1524         44.3              197                0    0   \n",
       "4                    1641         35.4               34                0    0   \n",
       "\n",
       "   HDF  PWF  OSF  RNF  \n",
       "0    0    0    0    0  \n",
       "1    0    0    0    0  \n",
       "2    0    0    0    0  \n",
       "3    0    0    0    0  \n",
       "4    0    0    0    0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd58bf20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(30,6))\n",
    "plt.scatter(dataset[\"Air temperature [K]\"], dataset[\"RNF\"])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b6080dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                             1\n",
      "Product ID                     0\n",
      "Type                       32152\n",
      "Air temperature [K]            0\n",
      "Process temperature [K]        0\n",
      "Rotational speed [rpm]         0\n",
      "Torque [Nm]                    0\n",
      "Tool wear [min]                0\n",
      "Machine failure             2148\n",
      "TWF                          212\n",
      "HDF                          704\n",
      "PWF                          327\n",
      "OSF                          540\n",
      "RNF                          308\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                              1\n",
       "Product ID                      0\n",
       "Type                        95354\n",
       "Air temperature [K]             0\n",
       "Process temperature [K]         0\n",
       "Rotational speed [rpm]          0\n",
       "Torque [Nm]                     0\n",
       "Tool wear [min]              3790\n",
       "Machine failure            134281\n",
       "TWF                        136217\n",
       "HDF                        135725\n",
       "PWF                        136102\n",
       "OSF                        135889\n",
       "RNF                        136121\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the occurrences of each category\n",
    "not_failed_h = (dataset == 0).sum()\n",
    "failed_h = (dataset == 1).sum()\n",
    "print(failed_h)\n",
    "not_failed_h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73ec8652",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'label' must be of length 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Plot the pie chart\u001b[39;00m\n\u001b[0;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m---> 12\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpie\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautopct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m%1.1f\u001b[39;49;00m\u001b[38;5;132;43;01m%%\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstartangle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m90\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset - Class Proportions\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mequal\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Equal aspect ratio ensures that pie is drawn as a circle.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\pyplot.py:2799\u001b[0m, in \u001b[0;36mpie\u001b[1;34m(x, explode, labels, colors, autopct, pctdistance, shadow, labeldistance, startangle, radius, counterclock, wedgeprops, textprops, center, frame, rotatelabels, normalize, hatch, data)\u001b[0m\n\u001b[0;32m   2792\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mpie)\n\u001b[0;32m   2793\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpie\u001b[39m(\n\u001b[0;32m   2794\u001b[0m         x, explode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, colors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, autopct\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2797\u001b[0m         textprops\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, center\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), frame\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   2798\u001b[0m         rotatelabels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, hatch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 2799\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpie\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2800\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexplode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2801\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautopct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautopct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpctdistance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpctdistance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshadow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshadow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2802\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabeldistance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabeldistance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstartangle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartangle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2803\u001b[0m \u001b[43m        \u001b[49m\u001b[43mradius\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mradius\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcounterclock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcounterclock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2804\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwedgeprops\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwedgeprops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtextprops\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtextprops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2805\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrotatelabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrotatelabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2806\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\__init__.py:1472\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m   1470\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1472\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1474\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1475\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[0;32m   1476\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\axes\\_axes.py:3209\u001b[0m, in \u001b[0;36mAxes.pie\u001b[1;34m(self, x, explode, labels, colors, autopct, pctdistance, shadow, labeldistance, startangle, radius, counterclock, wedgeprops, textprops, center, frame, rotatelabels, normalize, hatch)\u001b[0m\n\u001b[0;32m   3207\u001b[0m     explode \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(x)\n\u001b[0;32m   3208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(labels):\n\u001b[1;32m-> 3209\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be of length \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(explode):\n\u001b[0;32m   3211\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexplode\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be of length \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: 'label' must be of length 'x'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count the occurrences of each class (1 and 0)\n",
    "class_counts = {}\n",
    "for value in dataset:\n",
    "    class_counts[value] = class_counts.get(value, 0) + 1\n",
    "\n",
    "# Extract class labels and counts\n",
    "class_labels = ['not failed h', 'failed h']#list(class_counts.keys())\n",
    "class_counts = list(class_counts.values())\n",
    "\n",
    "# Plot the pie chart\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.pie(class_counts, labels=class_labels, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('dataset - Class Proportions')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae5978a",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_failed = (dataset['Machine failure'] == 0).sum()\n",
    "failed = (dataset['Machine failure'] == 1).sum()\n",
    "print(failed)\n",
    "not_failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd5b0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each class (1 and 0)\n",
    "class_counts = {}\n",
    "for value in dataset['Machine failure']:\n",
    "    class_counts[value] = class_counts.get(value, 0) + 1\n",
    "\n",
    "# Extract class labels and counts\n",
    "class_labels = ['not failed', 'failed']#list(class_counts.keys())\n",
    "class_counts = list(class_counts.values())\n",
    "\n",
    "# Plot the pie chart\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.pie(class_counts, labels=class_labels, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Machine Failure - Class Proportions')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73f63d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b2649f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## checking the correlation\n",
    "data_corr = dataset.corr(method = 'pearson') ## using pandas\n",
    "data_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0736225e",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = plt.subplots(figsize=(21,15))\n",
    "hm = sns.heatmap(data=data_corr, square = True, annot = True) ### printing the labels of the data in the heatmap\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d88c892",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77eb4d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### creating data cleaning pipeline\n",
    "def removing_column(dataset):\n",
    "    dataset = dataset.drop('Product ID', axis=1)\n",
    "    return dataset\n",
    "\n",
    "## changing the datatype to categorical data\n",
    "\n",
    "def remove_missing_values(dataset):\n",
    "    # Remove rows with missing values (NaN or empty strings)\n",
    "    dataset = dataset.dropna(subset=['Type', 'Air temperature [K]', 'Process temperature [K]','Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]', 'Machine failure', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF'], how='all')\n",
    "    return dataset\n",
    "\n",
    "def removing_duplicates(dataset):\n",
    "    dataset = dataset.drop_duplicates(subset=['Type', 'Air temperature [K]', 'Process temperature [K]','Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]', 'Machine failure', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF'])\n",
    "    return dataset\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f024d178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning_pipeline(dataset):\n",
    "    dataset = removing_column(dataset)\n",
    "    dataset = remove_missing_values(dataset)\n",
    "    dataset = removing_duplicates(dataset)\n",
    "    return dataset\n",
    "      \n",
    "cleaned_dataset = data_cleaning_pipeline(dataset)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e39e36fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]\n",
       "Categories (3, int64): [0, 1, 2]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset[\"Type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3dae31c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Type</th>\n",
       "      <th>Air temperature [K]</th>\n",
       "      <th>Process temperature [K]</th>\n",
       "      <th>Rotational speed [rpm]</th>\n",
       "      <th>Torque [Nm]</th>\n",
       "      <th>Tool wear [min]</th>\n",
       "      <th>Machine failure</th>\n",
       "      <th>TWF</th>\n",
       "      <th>HDF</th>\n",
       "      <th>PWF</th>\n",
       "      <th>OSF</th>\n",
       "      <th>RNF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>300.6</td>\n",
       "      <td>309.6</td>\n",
       "      <td>1596</td>\n",
       "      <td>36.1</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>302.6</td>\n",
       "      <td>312.1</td>\n",
       "      <td>1759</td>\n",
       "      <td>29.1</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>299.3</td>\n",
       "      <td>308.5</td>\n",
       "      <td>1805</td>\n",
       "      <td>26.5</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>310.9</td>\n",
       "      <td>1524</td>\n",
       "      <td>44.3</td>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>298.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>1641</td>\n",
       "      <td>35.4</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id Type  Air temperature [K]  Process temperature [K]  \\\n",
       "0   0    0                300.6                    309.6   \n",
       "1   1    1                302.6                    312.1   \n",
       "2   2    0                299.3                    308.5   \n",
       "3   3    0                301.0                    310.9   \n",
       "4   4    1                298.0                    309.0   \n",
       "\n",
       "   Rotational speed [rpm]  Torque [Nm]  Tool wear [min]  Machine failure  TWF  \\\n",
       "0                    1596         36.1              140                0    0   \n",
       "1                    1759         29.1              200                0    0   \n",
       "2                    1805         26.5               25                0    0   \n",
       "3                    1524         44.3              197                0    0   \n",
       "4                    1641         35.4               34                0    0   \n",
       "\n",
       "   HDF  PWF  OSF  RNF  \n",
       "0    0    0    0    0  \n",
       "1    0    0    0    0  \n",
       "2    0    0    0    0  \n",
       "3    0    0    0    0  \n",
       "4    0    0    0    0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e6019e",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1b8312b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## horizontal spliting \n",
    "X = cleaned_dataset.iloc[:,[0,1,2,3,4,5,6,8,9,10,11,12]]\n",
    "y = cleaned_dataset['Machine failure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2071f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Type</th>\n",
       "      <th>Air temperature [K]</th>\n",
       "      <th>Process temperature [K]</th>\n",
       "      <th>Rotational speed [rpm]</th>\n",
       "      <th>Torque [Nm]</th>\n",
       "      <th>Tool wear [min]</th>\n",
       "      <th>TWF</th>\n",
       "      <th>HDF</th>\n",
       "      <th>PWF</th>\n",
       "      <th>OSF</th>\n",
       "      <th>RNF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>300.6</td>\n",
       "      <td>309.6</td>\n",
       "      <td>1596</td>\n",
       "      <td>36.1</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>302.6</td>\n",
       "      <td>312.1</td>\n",
       "      <td>1759</td>\n",
       "      <td>29.1</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>299.3</td>\n",
       "      <td>308.5</td>\n",
       "      <td>1805</td>\n",
       "      <td>26.5</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>310.9</td>\n",
       "      <td>1524</td>\n",
       "      <td>44.3</td>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>298.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>1641</td>\n",
       "      <td>35.4</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id Type  Air temperature [K]  Process temperature [K]  \\\n",
       "0   0    0                300.6                    309.6   \n",
       "1   1    1                302.6                    312.1   \n",
       "2   2    0                299.3                    308.5   \n",
       "3   3    0                301.0                    310.9   \n",
       "4   4    1                298.0                    309.0   \n",
       "\n",
       "   Rotational speed [rpm]  Torque [Nm]  Tool wear [min]  TWF  HDF  PWF  OSF  \\\n",
       "0                    1596         36.1              140    0    0    0    0   \n",
       "1                    1759         29.1              200    0    0    0    0   \n",
       "2                    1805         26.5               25    0    0    0    0   \n",
       "3                    1524         44.3              197    0    0    0    0   \n",
       "4                    1641         35.4               34    0    0    0    0   \n",
       "\n",
       "   RNF  \n",
       "0    0  \n",
       "1    0  \n",
       "2    0  \n",
       "3    0  \n",
       "4    0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55f9a833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a logistic regression model\n",
    "logreg_model = LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e5d83c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "98.4/1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51317de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.9842543  0.98495657 0.98484568 0.98410586 0.98432764]\n",
      "Mean cross-validation score: 0.9844980109665744\n"
     ]
    }
   ],
   "source": [
    "# Perform k-fold cross-validation (e.g., k=5)\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "#5 ## the equal spliting of the data\n",
    "cv_scores = cross_val_score(logreg_model, X, y, cv=k_fold)\n",
    "\n",
    "# Print the cross-validation scores and the mean score\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean cross-validation score:\", np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aaa6d1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_balanced, y_balanced = smote.fit_resample(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffedf2a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m num_folds \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m----> 2\u001b[0m cv_scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogreg_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_balanced\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_balanced\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_folds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    560\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 562\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:328\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    308\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m    309\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    310\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    311\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[0;32m    326\u001b[0m )\n\u001b[1;32m--> 328\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    408\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    409\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    412\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    413\u001b[0m     )\n\u001b[1;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    417\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    419\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    424\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    }
   ],
   "source": [
    "num_folds = 5\n",
    "cv_scores = cross_val_score(logreg_model, X_balanced, y_balanced, cv=num_folds, scoring='accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06adb9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a096d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4f41090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the folds\n",
    "for fold_num, (train_index, test_index) in enumerate(k_fold.split(X)):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "343a4af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27054"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### test\n",
    "len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7482589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred= [0] * len(y_val) ### 0s, the same length as test length\n",
    "pred\n",
    "#### test vs pred using accuracy as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dae6e3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9839949730169291\n"
     ]
    }
   ],
   "source": [
    "#### test vs pred using accuracy as metrics\n",
    "\n",
    "# Initialize variables for correct and total predictions\n",
    "correct_predictions = 0\n",
    "total_predictions = len(pred)\n",
    "\n",
    "# Calculate the number of correct predictions\n",
    "for pred, actual in zip(pred, y_val):\n",
    "    if pred == actual:\n",
    "        correct_predictions += 1\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc7bda4",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a8370fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Accuracy Scores:\n",
      "[0.98754389 0.9914988  0.99105526 0.99142456 0.99441857]\n",
      "Mean Accuracy: 0.9911882154361749\n",
      "Standard Deviation: 0.0021856936099778007\n"
     ]
    }
   ],
   "source": [
    "# Create a decision tree classifier with custom class weights\n",
    "# We assign a higher weight to the minority class (class 1) to make it more influential during training\n",
    "dt_classifier = DecisionTreeClassifier(class_weight={0:582 , 1: 477976})\n",
    "\n",
    "# Perform cross-validation with balanced data and custom class weights\n",
    "num_folds = 5\n",
    "cv_scores = cross_val_score(dt_classifier, X, y, cv=num_folds, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation results\n",
    "print(\"Cross-validation Accuracy Scores:\")\n",
    "print(cv_scores)\n",
    "print(\"Mean Accuracy:\", np.mean(cv_scores))\n",
    "print(\"Standard Deviation:\", np.std(cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d086ed72",
   "metadata": {},
   "source": [
    "## Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b0e09307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Accuracy Scores:\n",
      "[0.9962299  0.99619294 0.99637775 0.99608191 0.99541657]\n",
      "Mean Accuracy: 0.996059815180074\n",
      "Standard Deviation: 0.0003352553805331045\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(class_weight={0: 500, 1: 1500})\n",
    "\n",
    "# Perform cross-validation with balanced data and custom class weights\n",
    "num_folds = 5\n",
    "cv_scores = cross_val_score(rf_classifier, X, y, cv=num_folds, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation results\n",
    "print(\"Cross-validation Accuracy Scores:\")\n",
    "print(cv_scores)\n",
    "print(\"Mean Accuracy:\", np.mean(cv_scores))\n",
    "print(\"Standard Deviation:\", np.std(cv_scores))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9616e4",
   "metadata": {},
   "source": [
    "## KNeigbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "134d8270",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3858816300.py, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[38], line 21\u001b[1;36m\u001b[0m\n\u001b[1;33m    except Exception as e:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Apply SMOTE to oversample the minority class\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Create a K-Nearest Neighbors classifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
    "\n",
    "\n",
    "# Perform cross-validation with balanced data and custom class weights\n",
    "num_folds = 5\n",
    "cv_scores = cross_val_score(knn_classifier, X_resampled, y_resampled, cv=num_folds, scoring='accuracy')\n",
    "\n",
    "\n",
    "\n",
    "# Print cross-validation results\n",
    "print(\"Cross-validation Accuracy Scores:\")\n",
    "print(cv_scores)\n",
    "print(\"Mean Accuracy:\", np.mean(cv_scores))\n",
    "print(\"Standard Deviation:\", np.std(cv_scores))\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error occurred during cross-validation:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4be790b",
   "metadata": {},
   "source": [
    "## Spliting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "250063c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_x = X.drop(columns=['Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "31a4f7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##imputer = SimpleImputer(strategy='mean')\n",
    "##X_imputed = imputer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d09086f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to oversample the minority class in the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "844b6dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train_resampled, y_train_resampled, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f0477d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values per column:\n",
      "id                         0\n",
      "Air temperature [K]        0\n",
      "Process temperature [K]    0\n",
      "Rotational speed [rpm]     0\n",
      "Torque [Nm]                0\n",
      "Tool wear [min]            0\n",
      "TWF                        0\n",
      "HDF                        0\n",
      "PWF                        0\n",
      "OSF                        0\n",
      "RNF                        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of missing values per column:\")\n",
    "print(X_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9d134756",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Air temperature [K]</th>\n",
       "      <th>Process temperature [K]</th>\n",
       "      <th>Rotational speed [rpm]</th>\n",
       "      <th>Torque [Nm]</th>\n",
       "      <th>Tool wear [min]</th>\n",
       "      <th>TWF</th>\n",
       "      <th>HDF</th>\n",
       "      <th>PWF</th>\n",
       "      <th>OSF</th>\n",
       "      <th>RNF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>259519</th>\n",
       "      <td>107812</td>\n",
       "      <td>303.292958</td>\n",
       "      <td>311.373759</td>\n",
       "      <td>1333</td>\n",
       "      <td>52.017273</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>3000</td>\n",
       "      <td>298.800000</td>\n",
       "      <td>308.600000</td>\n",
       "      <td>1450</td>\n",
       "      <td>48.800000</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108647</th>\n",
       "      <td>109423</td>\n",
       "      <td>298.000000</td>\n",
       "      <td>307.700000</td>\n",
       "      <td>1508</td>\n",
       "      <td>40.300000</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130701</th>\n",
       "      <td>131791</td>\n",
       "      <td>301.600000</td>\n",
       "      <td>311.100000</td>\n",
       "      <td>1415</td>\n",
       "      <td>46.500000</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221342</th>\n",
       "      <td>105555</td>\n",
       "      <td>302.394346</td>\n",
       "      <td>310.914135</td>\n",
       "      <td>1352</td>\n",
       "      <td>53.766794</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35477</th>\n",
       "      <td>35567</td>\n",
       "      <td>297.800000</td>\n",
       "      <td>309.200000</td>\n",
       "      <td>1526</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74911</th>\n",
       "      <td>75302</td>\n",
       "      <td>297.600000</td>\n",
       "      <td>308.500000</td>\n",
       "      <td>1423</td>\n",
       "      <td>43.200000</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249918</th>\n",
       "      <td>54673</td>\n",
       "      <td>302.425247</td>\n",
       "      <td>310.250494</td>\n",
       "      <td>1375</td>\n",
       "      <td>52.550056</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119857</th>\n",
       "      <td>120775</td>\n",
       "      <td>300.400000</td>\n",
       "      <td>311.700000</td>\n",
       "      <td>1520</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>167</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187277</th>\n",
       "      <td>112455</td>\n",
       "      <td>302.584184</td>\n",
       "      <td>311.963611</td>\n",
       "      <td>1397</td>\n",
       "      <td>46.421204</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53258 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  Air temperature [K]  Process temperature [K]  \\\n",
       "259519  107812           303.292958               311.373759   \n",
       "2999      3000           298.800000               308.600000   \n",
       "108647  109423           298.000000               307.700000   \n",
       "130701  131791           301.600000               311.100000   \n",
       "221342  105555           302.394346               310.914135   \n",
       "...        ...                  ...                      ...   \n",
       "35477    35567           297.800000               309.200000   \n",
       "74911    75302           297.600000               308.500000   \n",
       "249918   54673           302.425247               310.250494   \n",
       "119857  120775           300.400000               311.700000   \n",
       "187277  112455           302.584184               311.963611   \n",
       "\n",
       "        Rotational speed [rpm]  Torque [Nm]  Tool wear [min]  TWF  HDF  PWF  \\\n",
       "259519                    1333    52.017273               24    0    0    0   \n",
       "2999                      1450    48.800000               81    0    0    0   \n",
       "108647                    1508    40.300000              200    0    0    0   \n",
       "130701                    1415    46.500000               82    0    0    0   \n",
       "221342                    1352    53.766794              125    0    0    0   \n",
       "...                        ...          ...              ...  ...  ...  ...   \n",
       "35477                     1526    41.500000              104    0    0    0   \n",
       "74911                     1423    43.200000              151    0    0    0   \n",
       "249918                    1375    52.550056               77    0    0    0   \n",
       "119857                    1520    42.000000              167    0    0    0   \n",
       "187277                    1397    46.421204              198    0    0    0   \n",
       "\n",
       "        OSF  RNF  \n",
       "259519    0    0  \n",
       "2999      0    0  \n",
       "108647    0    0  \n",
       "130701    0    0  \n",
       "221342    0    0  \n",
       "...     ...  ...  \n",
       "35477     0    0  \n",
       "74911     0    0  \n",
       "249918    0    0  \n",
       "119857    0    0  \n",
       "187277    0    0  \n",
       "\n",
       "[53258 rows x 11 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##X_train.drop(columns=['Type'])\n",
    "##X_test.drop(columns=['Type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654ff4d3",
   "metadata": {},
   "source": [
    "## logistic reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e877ef81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7581396222163806\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76     26610\n",
      "           1       0.77      0.74      0.75     26648\n",
      "\n",
      "    accuracy                           0.76     53258\n",
      "   macro avg       0.76      0.76      0.76     53258\n",
      "weighted avg       0.76      0.76      0.76     53258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a logistic regression classifier\n",
    "log_classifier = LogisticRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "log_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = log_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier's performance\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392ea1bc",
   "metadata": {},
   "source": [
    "## hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2abb969f",
   "metadata": {},
   "outputs": [],
   "source": [
    " ## Define hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6d8942bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "30 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan 0.77415857        nan 0.78397878        nan 0.77455757\n",
      "        nan 0.78875745        nan 0.78251889        nan 0.77980097]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 1, 'penalty': 'l2'}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76     26610\n",
      "           1       0.77      0.74      0.75     26648\n",
      "\n",
      "    accuracy                           0.76     53258\n",
      "   macro avg       0.76      0.76      0.76     53258\n",
      "weighted avg       0.76      0.76      0.76     53258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create GridSearchCV with logistic regression and hyperparameter grid\n",
    "grid_search = GridSearchCV(log_classifier, param_grid, cv=5)\n",
    "\n",
    "# Perform hyperparameter tuning on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters from the search\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Get the best logistic regression model with the best hyperparameters\n",
    "best_logreg_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test set using the best model\n",
    "y_pred = best_logreg_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "472f9794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities:\n",
      "[[0.86334155 0.13665845]\n",
      " [0.94477225 0.05522775]\n",
      " [0.80726967 0.19273033]\n",
      " ...\n",
      " [0.47546034 0.52453966]\n",
      " [0.72612459 0.27387541]\n",
      " [0.86551689 0.13448311]]\n"
     ]
    }
   ],
   "source": [
    " ##Predict probabilities on the test set using the best model\n",
    "l_prob = best_logreg_model.predict_proba(test)\n",
    "\n",
    "# The probabilities for each sample are stored in y_probabilities\n",
    "print(\"Probabilities:\")\n",
    "print(l_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "095644ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90954"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_l = np.maximum(l_prob[:, 0], l_prob[:, 1])\n",
    "len(prob_l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "72adba49",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = {\n",
    "    'ID': test['id'],\n",
    "    'Machine failure': prob_l\n",
    "}\n",
    "submission = pd.DataFrame(submission)\n",
    "submission\n",
    "submission.to_csv('7th submission.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a6cc718a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities:\n",
      "[[0.57566891 0.42433109]\n",
      " [0.42523011 0.57476989]\n",
      " [0.51244232 0.48755768]\n",
      " ...\n",
      " [0.38200884 0.61799116]\n",
      " [0.53095981 0.46904019]\n",
      " [0.42358907 0.57641093]]\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities on the test set\n",
    "y_probabilities = log_classifier.predict_proba(X_test)\n",
    "\n",
    "# The probabilities for each sample are stored in y_probabilities\n",
    "print(\"Probabilities:\")\n",
    "print(y_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e5530c",
   "metadata": {},
   "source": [
    "## testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca1c5b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = ['Type', 'Product ID']\n",
    "test=  test.drop(columns=columns_to_remove, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "91bb15e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = log_classifier.predict(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0df6d359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probabilities:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.86334155, 0.13665845],\n",
       "       [0.94477225, 0.05522775],\n",
       "       [0.80726967, 0.19273033],\n",
       "       ...,\n",
       "       [0.47546034, 0.52453966],\n",
       "       [0.72612459, 0.27387541],\n",
       "       [0.86551689, 0.13448311]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_probability = log_classifier.predict_proba(test)\n",
    "print('probabilities:')\n",
    "y_probability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7877afe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90954"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the higher probability between the two colum\n",
    "prob = np.maximum(y_probability[:, 0], y_probability[:, 1])\n",
    "len(prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d1d60467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90954"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bd3dc0c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "array length 53258 does not match index length 90954",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[117], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m submission \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m: test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProbability\u001b[39m\u001b[38;5;124m'\u001b[39m: prob\n\u001b[0;32m      4\u001b[0m }\n\u001b[1;32m----> 5\u001b[0m submission \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubmission\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m submission\n\u001b[0;32m      7\u001b[0m submission\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m7th submission.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\frame.py:664\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    658\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    659\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    660\u001b[0m     )\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 664\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    666\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    490\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    491\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\construction.py:680\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lengths[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m    676\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    677\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlengths[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    678\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    679\u001b[0m         )\n\u001b[1;32m--> 680\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    682\u001b[0m     index \u001b[38;5;241m=\u001b[39m default_index(lengths[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mValueError\u001b[0m: array length 53258 does not match index length 90954"
     ]
    }
   ],
   "source": [
    "submission = {\n",
    "    'ID': test['id'],\n",
    "    'Probability': prob\n",
    "}\n",
    "submission = pd.DataFrame(submission)\n",
    "submission\n",
    "submission.to_csv('7th submission.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5812fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5cccacf6",
   "metadata": {},
   "source": [
    "### Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "be096a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "##submit = pd.DataFrame({'ID':id,\n",
    "            ## 'Machine Failure': probability})\n",
    "### save to csv\n",
    "submission.to_csv('1st submission.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ca36cd",
   "metadata": {},
   "source": [
    "### decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "60d99012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9387134327237222\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94     26610\n",
      "           1       0.93      0.94      0.94     26648\n",
      "\n",
      "    accuracy                           0.94     53258\n",
      "   macro avg       0.94      0.94      0.94     53258\n",
      "weighted avg       0.94      0.94      0.94     53258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "de_tree=DecisionTreeClassifier()\n",
    "de_tree.fit(X_train, y_train)\n",
    "\n",
    "de_pred = de_tree.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier's performance\n",
    "print(\"Accuracy:\", accuracy_score(y_test, de_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, de_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3bc41239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities:\n",
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities on the test set\n",
    "y_probabilities = de_tree.predict_proba(X_test)\n",
    "\n",
    "# The probabilities for each sample are stored in y_probabilities\n",
    "print(\"Probabilities:\")\n",
    "print(y_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02429ae6",
   "metadata": {},
   "source": [
    "### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "190c3815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probabilities:\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "y_prob = de_tree.predict_proba(test)\n",
    "print('probabilities:')\n",
    "print(y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7e982d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90954"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the higher probability between the two colum\n",
    "d_prob = np.maximum(y_prob[:, 0], y_prob[:, 1])\n",
    "len(d_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3e611b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90954"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "16ca6d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Machine faliure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136429</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>136430</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>136431</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136432</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>136433</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90949</th>\n",
       "      <td>227378</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90950</th>\n",
       "      <td>227379</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90951</th>\n",
       "      <td>227380</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90952</th>\n",
       "      <td>227381</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90953</th>\n",
       "      <td>227382</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90954 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  Machine faliure\n",
       "0      136429              1.0\n",
       "1      136430              1.0\n",
       "2      136431              1.0\n",
       "3      136432              1.0\n",
       "4      136433              1.0\n",
       "...       ...              ...\n",
       "90949  227378              1.0\n",
       "90950  227379              1.0\n",
       "90951  227380              1.0\n",
       "90952  227381              1.0\n",
       "90953  227382              1.0\n",
       "\n",
       "[90954 rows x 2 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##creating a csv to save the dataset\n",
    "submission = {\n",
    "    'id': test['id'],\n",
    "    'Machine faliure': d_prob\n",
    "}\n",
    "submission = pd.DataFrame(submission)\n",
    "\n",
    "submission.to_csv('4th submission.csv',index = False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520efaf5",
   "metadata": {},
   "source": [
    "## knneigbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "70dd7a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9228097187277029\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.92     26610\n",
      "           1       0.88      0.97      0.93     26648\n",
      "\n",
      "    accuracy                           0.92     53258\n",
      "   macro avg       0.93      0.92      0.92     53258\n",
      "weighted avg       0.93      0.92      0.92     53258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a logistic regression classifier\n",
    "knn_neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Fit the model on the training data\n",
    "knn_neigh.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "k_pred = knn_neigh.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier's performance\n",
    "print(\"Accuracy:\", accuracy_score(y_test, k_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, k_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "219ecf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities:\n",
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities on the test set\n",
    "k_probabilities = knn_neigh.predict_proba(X_test)\n",
    "\n",
    "# The probabilities for each sample are stored in y_probabilities\n",
    "print(\"Probabilities:\")\n",
    "print(k_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177ec52c",
   "metadata": {},
   "source": [
    "## testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "eff20653",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = knn_neigh.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d3198b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probabilities:\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "k_prob = knn_neigh.predict_proba(test)\n",
    "print('probabilities:')\n",
    "print(k_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6302c883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90954"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the higher probability between the two colum\n",
    "k_prob = np.maximum(k_prob[:, 0], k_prob[:, 1])\n",
    "len(k_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a18cff71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Machine faliure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136429</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>136430</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>136431</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136432</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>136433</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90949</th>\n",
       "      <td>227378</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90950</th>\n",
       "      <td>227379</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90951</th>\n",
       "      <td>227380</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90952</th>\n",
       "      <td>227381</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90953</th>\n",
       "      <td>227382</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90954 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  Machine faliure\n",
       "0      136429              1.0\n",
       "1      136430              1.0\n",
       "2      136431              1.0\n",
       "3      136432              1.0\n",
       "4      136433              1.0\n",
       "...       ...              ...\n",
       "90949  227378              1.0\n",
       "90950  227379              1.0\n",
       "90951  227380              1.0\n",
       "90952  227381              1.0\n",
       "90953  227382              1.0\n",
       "\n",
       "[90954 rows x 2 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##creating a csv to save the dataset\n",
    "submission = {\n",
    "    'id': test['id'],\n",
    "    'Machine faliure': k_prob\n",
    "}\n",
    "submission = pd.DataFrame(submission)\n",
    "\n",
    "submission.to_csv('5th submission.csv',index = False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396100d5",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f4ed3c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9597994667467799\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96     26610\n",
      "           1       0.96      0.96      0.96     26648\n",
      "\n",
      "    accuracy                           0.96     53258\n",
      "   macro avg       0.96      0.96      0.96     53258\n",
      "weighted avg       0.96      0.96      0.96     53258\n",
      "\n"
     ]
    }
   ],
   "source": [
    " ## Create a logistic regression classifier\n",
    "random_for = RandomForestClassifier()\n",
    "# Fit the model on the training data\n",
    "random_for.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "R_pred = random_for.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier's performance\n",
    "print(\"Accuracy:\", accuracy_score(y_test, R_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, R_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "457e863d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities:\n",
      "[[0.01 0.99]\n",
      " [0.91 0.09]\n",
      " [0.89 0.11]\n",
      " ...\n",
      " [0.01 0.99]\n",
      " [1.   0.  ]\n",
      " [0.05 0.95]]\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities on the test set\n",
    "r_probabilities = random_for.predict_proba(X_test)\n",
    "\n",
    "# The probabilities for each sample are stored in y_probabilities\n",
    "print(\"Probabilities:\")\n",
    "print(r_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46c5855",
   "metadata": {},
   "source": [
    "### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "40f7dfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probabilities:\n",
      "[[0.82 0.18]\n",
      " [0.96 0.04]\n",
      " [0.99 0.01]\n",
      " ...\n",
      " [1.   0.  ]\n",
      " [0.98 0.02]\n",
      " [0.99 0.01]]\n"
     ]
    }
   ],
   "source": [
    "r_prob = random_for.predict_proba(test)\n",
    "print('probabilities:')\n",
    "print(r_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0f0dcfdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90954"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the higher probability between the two colum\n",
    "ra_prob = np.maximum(r_prob[:, 0], r_prob[:, 1])\n",
    "len(k_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "85b381d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Machine faliure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136429</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>136430</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>136431</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136432</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>136433</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90949</th>\n",
       "      <td>227378</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90950</th>\n",
       "      <td>227379</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90951</th>\n",
       "      <td>227380</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90952</th>\n",
       "      <td>227381</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90953</th>\n",
       "      <td>227382</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90954 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  Machine faliure\n",
       "0      136429             0.82\n",
       "1      136430             0.96\n",
       "2      136431             0.99\n",
       "3      136432             0.98\n",
       "4      136433             0.97\n",
       "...       ...              ...\n",
       "90949  227378             0.97\n",
       "90950  227379             1.00\n",
       "90951  227380             1.00\n",
       "90952  227381             0.98\n",
       "90953  227382             0.99\n",
       "\n",
       "[90954 rows x 2 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##creating a csv to save the dataset\n",
    "submission = {\n",
    "    'id': test['id'],\n",
    "    'Machine faliure': ra_prob\n",
    "}\n",
    "submission = pd.DataFrame(submission)\n",
    "\n",
    "submission.to_csv('6th submission.csv',index = False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef59c5ad",
   "metadata": {},
   "source": [
    "### hyper perameter tunning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d6a351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'max_depth': [None, 5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt']\n",
    "}\n",
    "\n",
    "# Create RandomizedSearchCV with Random Forest and hyperparameter grid\n",
    "random_search = RandomizedSearchCV(random_for, param_distributions=param_grid, n_iter=10, cv=5, random_state=42)\n",
    "\n",
    "# Perform hyperparameter tuning on the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters from the search\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "# Get the best Random Forest model with the best hyperparameters\n",
    "best_rf_model = random_search.best_estimator_\n",
    "\n",
    "# Predict on the test set using the best model\n",
    "random_pred = best_rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, random_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c281a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities on the test set\n",
    "prob_R = best_rf_model.predict_proba(test)\n",
    "\n",
    "# The probabilities for each sample are stored in y_probabilities\n",
    "print(\"Probabilities:\")\n",
    "print(prob_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dba258",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_r = np.maximum(prob_R[:, 0], prob_R[:, 1])\n",
    "len(prob_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd385b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "##creating a csv to save the dataset\n",
    "submission = {\n",
    "    'id': test['id'],\n",
    "    'Machine failure': prob_r\n",
    "}\n",
    "submission = pd.DataFrame(submission)\n",
    "\n",
    "submission.to_csv('8th submission.csv',index = False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cad11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create individual classifiers\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Create an ensemble using VotingClassifier\n",
    "ensemble_classifier = VotingClassifier(estimators=[\n",
    "    ('knn', knn_classifier),\n",
    "    ('rf', rf_classifier)\n",
    "], voting='soft')  # You can use 'hard' or 'soft' voting\n",
    "\n",
    "# Train the ensemble classifier\n",
    "ensemble_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = ensemble_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Ensemble Classifier Accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
